{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_5MY5mx-Xvt"
      },
      "source": [
        "# RAG\n",
        "\n",
        "### **What is RAG and how is it different from LLM?**\n",
        "\n",
        "**RAG** combines LLMs with a retrieval system to improve efficency of the model and provide up-to-date data\n",
        "\n",
        "**Difference between RAG and LLM**\n",
        "\n",
        "Due to static training data LLMs have limited knowledge, whereas RAG allows LLMs to access up-to-date information from external sources. RAG enhance the capabilities of LLMs, making them more accurate\n",
        "\n",
        "[Difference between LLM & RAG](https://cgorale111.medium.com/difference-between-llm-rag-d960ec942b88)\n",
        "\n",
        "### **What is a vector database? Give some examples.**\n",
        "\n",
        "**Vector Database**\n",
        "- Pool of Embedding\n",
        "- Fast retrieval and similarity search\n",
        "- Cosine distance, Dot product and Euclidean distance\n",
        "- Algorithm, LSH (Locality-Sensitive Hashing)\n",
        "\n",
        "**Examples**\n",
        "- Search Engines\n",
        "- Ad recommendations\n",
        "\n",
        "[Vector Databases: A Beginner’s Guide](https://medium.com/@raj.pulapakura/vector-databases-a-beginners-guide-723ce809f52b)\n",
        "\n",
        "### **What are vector distances? Give examples. Detail \"cosine distance”.**\n",
        "\n",
        "##Vector Distance\n",
        "\n",
        "Distance metric or similarity measure, is a mathematical function that quantifies the similarity or dissimilarity between two vectors.\n",
        "\n",
        "##Cosine Distance\n",
        "\n",
        "Cosine distance represent the similarity between the vectors. It ranges from 0 to 1. If the **distance is 0** they are **similar**.\n",
        "\n",
        "> Cosine Similarity = $\\frac{A \\cdot B}{\\|A\\| \\|B\\|}$\n",
        "\n",
        "```\n",
        "cosine distance = 1 - cosine similarity\n",
        "```\n",
        "[Cosine Similarity](https://youtu.be/m_CooIRM3UI?feature=shared)\n",
        "\n",
        "### **Explain the concept of \"reranking\" in RAG and how it differs from initial retrieval. What factors make a good reranker?**\n",
        "\n",
        "Reranking introduces  **two-stage retrieval process:**\n",
        "\n",
        "**Initial retrieval:** A fast, scalable method (like embedding-based similarity search) retrieves an initial set of candidate documents.\n",
        "\n",
        "**Reranking:** A more sophisticated model reorders these candidates based on relevance to the query.\n",
        "\n",
        "[Reranking](https://www.chatbase.co/blog/reranking)\n",
        "\n",
        "[Improving RAG Accuracy with Rerankers](https://www.infracloud.io/blogs/improving-rag-accuracy-with-rerankers/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzWgTxeAHlXp"
      },
      "source": [
        "**Make a pdf parsing pipeline from Llamaparse (specifically Llamaparse) and save it as markdown.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5vdk7oWAHnR",
        "outputId": "75bb1821-ab78-4b19-937a-2835b805479f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-parse\n",
            "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.21 (from llama-parse)\n",
            "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.21->llama-parse) (8.1.8)\n",
            "Collecting llama-cloud==0.1.19 (from llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
            "Collecting llama-index-core>=0.11.0 (from llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading llama_index_core-0.12.34.post1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.21->llama-parse) (4.3.7)\n",
            "Requirement already satisfied: pydantic!=2.10 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.21->llama-parse) (2.11.4)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.19->llama-cloud-services>=0.6.21->llama-parse) (2025.4.26)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.19->llama-cloud-services>=0.6.21->llama-parse) (0.28.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (3.11.15)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (1.2.18)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (2025.3.2)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (2.32.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (2.0.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (9.1.2)\n",
            "Collecting tiktoken>=0.7.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (4.13.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (1.17.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.21->llama-parse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.21->llama-parse) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.21->llama-parse) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (1.20.0)\n",
            "Collecting griffe (from banks<3,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (3.1.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud==0.1.19->llama-cloud-services>=0.6.21->llama-parse) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud==0.1.19->llama-cloud-services>=0.6.21->llama-parse) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud==0.1.19->llama-cloud-services>=0.6.21->llama-parse) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.19->llama-cloud-services>=0.6.21->llama-parse) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (3.2.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.19->llama-cloud-services>=0.6.21->llama-parse) (1.3.1)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.21->llama-parse) (3.0.2)\n",
            "Downloading llama_parse-0.6.21-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
            "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.12.34.post1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: filetype, dirtyjson, python-dotenv, mypy-extensions, marshmallow, colorama, typing-inspect, tiktoken, griffe, llama-cloud, dataclasses-json, banks, llama-index-core, llama-cloud-services, llama-parse\n",
            "Successfully installed banks-2.1.2 colorama-0.4.6 dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.7.3 llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-core-0.12.34.post1 llama-parse-0.6.21 marshmallow-3.26.1 mypy-extensions-1.1.0 python-dotenv-1.1.0 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-parse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX6G3aUqNQcl",
        "outputId": "c53d708d-a05f-4e1a-8ab0-e11edbfafb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-08 09:33:54--  https://drive.google.com/uc?export=download&id=1hhonyqnWh_KDV5VEFRbRQcJrzal6PAiA\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.132.101, 74.125.132.139, 74.125.132.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.132.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1hhonyqnWh_KDV5VEFRbRQcJrzal6PAiA&export=download [following]\n",
            "--2025-05-08 09:33:54--  https://drive.usercontent.google.com/download?id=1hhonyqnWh_KDV5VEFRbRQcJrzal6PAiA&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.194.132, 2607:f8b0:4001:c10::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 193635 (189K) [application/octet-stream]\n",
            "Saving to: ‘test.pdf’\n",
            "\n",
            "test.pdf            100%[===================>] 189.10K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-05-08 09:33:57 (93.3 MB/s) - ‘test.pdf’ saved [193635/193635]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O \"test.pdf\" \"https://drive.google.com/uc?export=download&id=1hhonyqnWh_KDV5VEFRbRQcJrzal6PAiA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM7oOi96FGg4",
        "outputId": "192c5658-65de-434c-d8f7-0fe92cab9528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started parsing the file under job_id aca8e08d-97de-4711-8d4d-7965f3d07edb\n",
            "# Optimization using Newton-Raphson Search\n",
            "\n",
            "# Nevin V Adatte\n",
            "\n",
            "# TVE24CSAI14\n",
            "\n",
            "# April 27, 2025\n",
            "\n",
            "# 1. Introduction\n",
            "\n",
            "Optimization is fundamental in engineering and scientific applications. The Newton-Raphson Search method is an iterative technique that uses the first and second derivatives of a function to find its minimum. In this document, we apply the Newton-Raphson method to the function:\n",
            "\n",
            "f(x) = x² − 2x − 3\n",
            "\n",
            "# 2. Newton-Raphson Search Method\n",
            "\n",
            "The Newton-Raphson method approximates the minimum of a function by iteratively updating an initial guess using the formula:\n",
            "\n",
            "xₙ₊₁ = xₙ − f′′′(xⁿ) / f (xₙ)\n",
            "\n",
            "where f′(x) and f′′(x) are the first and second derivatives, respectively. The steps are:\n",
            "\n",
            "1. Choose an initial guess x₀ and a tolerance ϵ.\n",
            "2. Compute the next approximation using the Newton-Raphson formula.\n",
            "3. Repeat until the change in x is less than ϵ or the maximum number of iterations is reached.\n",
            "\n",
            "# 3. Python Implementation\n",
            "\n",
            "Below is the Python code to perform the Newton-Raphson Search \n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"\"\n",
        "\n",
        "from llama_parse import LlamaParse\n",
        "\n",
        "document = LlamaParse(result_type=\"markdown\").load_data(\"/content/test.pdf\")\n",
        "\n",
        "print(document[0].text[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO5yWtHf-enN"
      },
      "source": [
        "# API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9J-_2x5-ip-"
      },
      "source": [
        "**What is an API ?**\n",
        "\n",
        "API (Application Programming Interface)\n",
        "\n",
        "Application sending the **request** is called the **client**, and the application sending the **response** is called the **server**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbF7ZIsh-o60"
      },
      "source": [
        "**List the types of API?**\n",
        "\n",
        "\n",
        "- Based on API Architectures\n",
        "  - SOAP (Simple Object Access Protocol): Client and server exchange messages using XML\n",
        "  - RPC (Remote Procedure Calls): Enable clients to call functions on a remote server\n",
        "  - Websocket: Enables real-time, bidirectional communication between client and server\n",
        "  - GraphQL: A query language for APIs that allows clients to specify exactly the data they need\n",
        "  - REST (Representational State Transfer): Uses standard HTTP methods (GET, POST, PUT, DELETE) for communication\n",
        "\n",
        "- Based on API Access Level\n",
        "  - Open/Public API: Accessible to external developers. Eg: Twitter API for fetching tweets\n",
        "  - Private/Internal API: Used within an organization, not exposed publicly. Eg: Internal employee management system API\n",
        "  - Partner API: Shared with specific partners under controlled access. Eg: Payment processor APIs for select merchants\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjctcGYU-qT0"
      },
      "source": [
        "**Key components of Rest API, HTTPS methods and its architecture.**\n",
        "\n",
        "**REST Key Components**\n",
        "\n",
        "1.  Resources: Any data or content that is accessible through the API, identified by a unique URI\n",
        "2.  Representations:Data format representing resource state (e.g., JSON, XML)\n",
        "3.  Hypermedia Links: Embedded links in responses to enable dynamic navigation\n",
        "\n",
        "**HTTPS Methods**\n",
        "\n",
        "- GET: Retrieves data from the server\n",
        "- POST: Creates a new resource on the server\n",
        "- PUT: Updates an existing resource on the server\n",
        "- DELETE: Removes a resource from the server\n",
        "- PATCH: Performs a partial update of a resource on the server\n",
        "\n",
        "\n",
        "[Rest API Architecture](https://medium.com/@shikha.ritu17/rest-api-architecture-6f1c3c99f0d3)\n",
        "\n",
        "[REST API Video](https://youtu.be/LzOtbUw6f_o?feature=shared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw1x-sFu-vX9"
      },
      "source": [
        "**What is webscraping?**\n",
        "\n",
        "It fetch the HTML code of a webpage and then extracting the specific data the user wants, like prices, product details, or articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU3CippexR8U"
      },
      "source": [
        "**Go to firecrawl.dev, create an account and scrape any website of choice using api method. Store the data into a text file.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSu6XS0AhBJc",
        "outputId": "5791b4de-77fd-43bf-ef11-ccf1562159d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to scraped_data.txt\n",
            "{\n",
            "    \"success\": true,\n",
            "    \"data\": {\n",
            "        \"markdown\": \"Hello, my name is\\n\\nNevin V Adatte\\n\\nAnd I'm a Studen\\\\|\\n\\n## About me\\n\\n![](https://nevin-adatte.github.io/Portfolio/images/19139%20copy%20Copy.jpg)\\n\\nI'm Nevin and I'm a Studen\\\\|\\n\\nI am an M.Tech student in AI at the College of Engineering Trivandrum, passionate about deep learning, computer vision, and natural language processing. I am also experienced in photo and video editing, using programs like Photoshop, Premiere Pro, and After Effects to bring my creative ideas to life.\\n\\n\\nIn addition to my technical skills, I am also proficient in Microsoft PowerPoint and enjoy creating visually appealing presentations that effectively communicate complex ideas. I am constantly seeking out new challenges and opportunities to expand my knowledge and skills, and I am excited to see where my passion for engineering and design will take me in the future.\\n\\n\\nThanks for stopping by my portfolio, and feel free to reach out if you have any questions or would like to work together on a project!\\n\\n## Projects\\n\\n[Traffic Sign Detection\\\\\\\\\\n\\\\\\\\\\nYOLOv5-based system that accurately identifies and classifies traffic signs](https://github.com/Nevin-Adatte/Real-Time-Traffic-Sign-Detection)\\n\\n[Switch Automation\\\\\\\\\\n\\\\\\\\\\nSmart switch system for remote control and augmented reality visualization](https://github.com/Nevin-Adatte/Switch-Automation)\\n\\n[Face Recognition\\\\\\\\\\n\\\\\\\\\\nApplication that can be used to retrieve images from database by compare user face](https://github.com/Nevin-Adatte/face_recognition)\\n\\n## My Skills\\n\\nMy creative skills & experience\\n\\nComputer Vision: : Hands-on experience with object detection, image processing, and facial recognition\\n\\n\\nAI for Automation : Building AI-driven systems for automation and smart decision-making\\n\\n\\nWeb Development : I have a strong foundation in web development using HTML, CSS, and JavaScript.\\n\\nVideo Editing : I am skilled in using Adobe Premiere Pro and After Effects to edit videos, add special effects, and create dynamic and engaging content.\\n\\n\\nPython90%\\n\\nC75%\\n\\nJavaScript65%\\n\\nHTML/CSS80%\\n\\nMySQL70%\\n\\n## Contact me\\n\\nGet in Touch\\n\\nYour satisfaction is my priority. Let's connect!\\n\\nName\\n\\nNevin V Adatte\\n\\nAddress\\n\\nKerala, India\\n\\nEmail\\n\\nnevinvadatte@gmail.com\",\n",
            "        \"metadata\": {\n",
            "            \"viewport\": \"width=device-width, initial-scale=1.0\",\n",
            "            \"language\": \"en\",\n",
            "            \"title\": \"Nevin | AI Engineer & Researcher\",\n",
            "            \"scrapeId\": \"c67aa853-86da-41b4-b005-0093ef3e1d0c\",\n",
            "            \"sourceURL\": \"https://nevin-adatte.github.io/Portfolio/\",\n",
            "            \"url\": \"https://nevin-adatte.github.io/Portfolio/\",\n",
            "            \"statusCode\": 200\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Replace with your actual FireCrawl API key\n",
        "api_key = \"\"\n",
        "\n",
        "# Replace with the website you want to scrape\n",
        "website_url = \"https://nevin-adatte.github.io/Portfolio/\"\n",
        "\n",
        "# FireCrawl API endpoint\n",
        "api_endpoint = \"https://api.firecrawl.dev/v1/scrape\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"url\": website_url,\n",
        "    # Add any other necessary parameters for your scrape request\n",
        "    # Example:  \"js_render\": True,  # Enable JavaScript rendering\n",
        "    #           \"extract_rules\": [{\"selector\": \"h1\", \"field\": \"title\"}] #Specify what to scrape\n",
        "}\n",
        "\n",
        "response = requests.post(api_endpoint, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    # Process the extracted data\n",
        "\n",
        "    # Example: Save data to a text file\n",
        "    filename = \"scraped_data.txt\"\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "      json.dump(data, f, indent=4)\n",
        "\n",
        "    print(f\"Data saved to {filename}\")\n",
        "\n",
        "    print(open(\"/content/scraped_data.txt\").read())\n",
        "else:\n",
        "    print(f\"Error: {response.status_code} - {response.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EyItsUVLPq_"
      },
      "source": [
        "#Chroma DB\n",
        "\n",
        "Chroma DB is an open-source vector database designed for the efficient storage and retrieval of vector embeddings.\n",
        "\n",
        "#Memory in langane\n",
        "\n",
        "LangChain’s memory system is built around two fundamental actions:\n",
        "\n",
        "**Reading:** Before a chain processes a user’s input, it reads from memory to add context (e.g., previous messages).\n",
        "\n",
        "**Writing:** After processing, it writes the current input and output to memory for future use.\n",
        "\n",
        "\n",
        "###Types of Memory:\n",
        "\n",
        "**Simple Memory:**  Stores context or other information that shouldn’t ever change between prompts.\n",
        "\n",
        "```\n",
        "class langchain.memory.simple.SimpleMemory\n",
        "```\n",
        "\n",
        "**Conversation Buffer Memory:** Stores the entire conversation history in a list.\n",
        "\n",
        "```\n",
        "class langchain.memory.buffer.ConversationBufferMemory\n",
        "```\n",
        "\n",
        "#Memory in llamindex\n",
        "\n",
        "In LlamaIndex, customize memory by using an existing BaseMemory class, or by creating a custom one. As the agent runs, it will make calls to *memory.put()* to store information, and *memory.get()* to retrieve information.\n",
        "\n",
        "#Few Short Prompt\n",
        "\n",
        "It's a technique used in AI, particularly with large language models, to guide the model's output by providing it with a small number of examples (or \"shots\") before asking it to perform a specific task. This contrasts with zero-shot prompting, where no examples are given, and one-shot prompting, where only a single example is provided. By offering these examples, few-shot prompting helps the model understand the desired output format, style, or specific instructions for a task.\n",
        "\n",
        "#Zero Short Prompt\n",
        "\n",
        "Zero-shot prompting is a technique in AI where a model is given a task to perform without any prior examples or specific training data for that task. The model relies on its pre-trained knowledge and general language understanding to generate a response.\n",
        "\n",
        "#LLM bench marking\n",
        "\n",
        "LLM benchmarks are standardized tests that assess LLM performance across various tasks. Typically, they check if the model can produce the correct known response to a given input. Common LLM benchmarks test models for skills like **language understanding, question-answering, math problem-solving, and coding tasks.**\n",
        "\n",
        "#FAST API\n",
        "\n",
        "FastAPI is a high-performance web framework for building HTTP-based service APIs in Python 3.8+.\n",
        "\n",
        "[FastAPI - Introduction](https://www.geeksforgeeks.org/python/fastapi-introduction/)\n",
        "\n",
        "#MCP - Model Condition Protocol\n",
        "\n",
        "[Introduction to MCP](https://modelcontextprotocol.io/introduction)\n",
        "\n",
        "#OCR-Rag\n",
        "\n",
        "**Optical Character Recognition** (OCR) enables the conversion of various documents — such as scanned papers, PDFs, or photos — into editable and searchable text. While OCR has made significant strides in accuracy, it primarily focuses on text extraction, often overlooking the contextual and visual elements present in complex documents."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
