{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Az_aC_iFlA0Q",
      "metadata": {
        "id": "Az_aC_iFlA0Q"
      },
      "source": [
        "# Lesson 1: Router Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357c97c9",
      "metadata": {
        "id": "357c97c9"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5f4f4a-5890-451c-8869-24606ef9f396",
      "metadata": {
        "height": 64,
        "id": "ab5f4f4a-5890-451c-8869-24606ef9f396",
        "tags": []
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
      "metadata": {
        "height": 64,
        "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49fca250",
      "metadata": {
        "id": "49fca250"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3ae2a8c",
      "metadata": {
        "id": "f3ae2a8c",
        "tags": []
      },
      "source": [
        "To download this paper, below is the needed code:\n",
        "\n",
        "`#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf`\n",
        "\n",
        "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UCwNVAHFqkBL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCwNVAHFqkBL",
        "outputId": "b7f91dee-b4a1-49c4-f7a1-fa6a7e2c0171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-06-29 11:25:04--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
            "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
            "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16911937 (16M) [application/pdf]\n",
            "Saving to: ‘metagpt.pdf’\n",
            "\n",
            "metagpt.pdf         100%[===================>]  16.13M  9.22MB/s    in 1.7s    \n",
            "\n",
            "2025-06-29 11:25:07 (9.22 MB/s) - ‘metagpt.pdf’ saved [16911937/16911937]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BChqo0YDq2CG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BChqo0YDq2CG",
        "outputId": "8a2674ac-6c6f-4e0f-f4b8-ba13125db93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.12.44-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl.metadata (439 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.2 (from llama_index)\n",
            "  Downloading llama_index_cli-0.4.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.44 (from llama_index)\n",
            "  Downloading llama_index_core-0.12.44-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_readers_file-0.4.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama_index) (1.91.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (3.11.15)\n",
            "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading banks-2.1.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (0.28.1)\n",
            "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading llama_index_workflows-1.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (2.32.3)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama_index) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (4.14.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.44->llama_index) (1.17.2)\n",
            "Collecting llama-cloud==0.1.26 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.26->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2025.6.15)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama_index) (4.13.4)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama_index) (2.2.2)\n",
            "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama_index)\n",
            "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama_index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.39-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama_index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama_index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama_index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama_index) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama_index) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama_index) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.44->llama_index) (1.20.1)\n",
            "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama_index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama_index) (4.3.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama_index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama_index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.44->llama_index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.44->llama_index) (0.16.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl.metadata (252 bytes)\n",
            "Collecting llama-cloud-services>=0.6.39 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama_index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama_index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama_index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.44->llama_index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama_index) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.44->llama_index) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.44->llama_index) (3.2.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.38-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.36 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.35 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.32->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.44->llama_index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama_index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama_index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.44->llama_index) (3.0.2)\n",
            "Downloading llama_index-0.12.44-py3-none-any.whl (7.1 kB)\n",
            "Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.44-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.7.7-py3-none-any.whl (16 kB)\n",
            "Downloading llama_cloud-0.1.26-py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.5.1-py3-none-any.whl (3.4 kB)\n",
            "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
            "Downloading llama_index_readers_file-0.4.9-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading banks-2.1.3-py3-none-any.whl (28 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-1.0.1-py3-none-any.whl (36 kB)\n",
            "Downloading llama_parse-0.6.34-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.34-py3-none-any.whl (39 kB)\n",
            "Downloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, setuptools, python-dotenv, pypdf, mypy-extensions, marshmallow, deprecated, colorama, aiosqlite, typing-inspect, griffe, llama-index-instrumentation, llama-cloud, dataclasses-json, banks, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiosqlite-0.21.0 banks-2.1.3 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.7.3 llama-cloud-0.1.26 llama-cloud-services-0.6.34 llama-index-agent-openai-0.4.12 llama-index-cli-0.4.3 llama-index-core-0.12.44 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.7.7 llama-index-instrumentation-0.2.0 llama-index-llms-openai-0.4.7 llama-index-multi-modal-llms-openai-0.5.1 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.9 llama-index-readers-llama-parse-0.4.0 llama-index-workflows-1.0.1 llama-parse-0.6.34 llama_index-0.12.44 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-5.7.0 python-dotenv-1.1.1 setuptools-80.9.0 striprtf-0.0.26 typing-inspect-0.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e3187606807d42e2bd6371709b46c11d",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install llama_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c7f012d-dcd3-4881-a568-72dd27d79159",
      "metadata": {
        "height": 96,
        "id": "5c7f012d-dcd3-4881-a568-72dd27d79159",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b48a301",
      "metadata": {
        "id": "6b48a301"
      },
      "source": [
        "## Define LLM and Embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
      "metadata": {
        "height": 96,
        "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0660ee-b231-4351-b158-d8ad023e00b5",
      "metadata": {
        "height": 130,
        "id": "de0660ee-b231-4351-b158-d8ad023e00b5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "997c7559",
      "metadata": {
        "id": "997c7559"
      },
      "source": [
        "## Define Summary Index and Vector Index over the Same Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ogs1_CtatvxL",
      "metadata": {
        "id": "ogs1_CtatvxL"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d01b01-bc74-432a-8d92-07b9e86498b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "height": 96,
        "id": "73d01b01-bc74-432a-8d92-07b9e86498b0",
        "outputId": "621e5ddc-4b08-4cb1-fb53-2503d3e808a6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9898d3f",
      "metadata": {
        "id": "f9898d3f"
      },
      "source": [
        "## Define Query Engines and Set Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44cd7046-c714-4920-b077-b3ded917862f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "height": 113,
        "id": "44cd7046-c714-4920-b077-b3ded917862f",
        "outputId": "4804ab6f-a2f3-4891-e480-5daf356a779c",
        "tags": []
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'vector_index' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-2321734846.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0muse_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvector_query_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_query_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vector_index' is not defined"
          ]
        }
      ],
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1d6d75-247e-426a-8ef4-b49225c24796",
      "metadata": {
        "height": 300,
        "id": "6a1d6d75-247e-426a-8ef4-b49225c24796",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to MetaGPT\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d2c152",
      "metadata": {
        "id": "98d2c152"
      },
      "source": [
        "## Define Router Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00734d7c-638a-4d63-ab1f-7f5a92a65119",
      "metadata": {
        "height": 232,
        "id": "00734d7c-638a-4d63-ab1f-7f5a92a65119",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3f0a76-68a8-444d-867f-d084bb3ff112",
      "metadata": {
        "height": 62,
        "id": "fe3f0a76-68a8-444d-867f-d084bb3ff112",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3fedea0-f2a9-46bb-8aaf-287df65b8fff",
      "metadata": {
        "height": 30,
        "id": "d3fedea0-f2a9-46bb-8aaf-287df65b8fff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(len(response.source_nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af8c31b3-8e22-4ad9-9825-b8de21bd03c0",
      "metadata": {
        "height": 96,
        "id": "af8c31b3-8e22-4ad9-9825-b8de21bd03c0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\n",
        "    \"How do agents share information with other agents?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed060ee",
      "metadata": {
        "id": "aed060ee"
      },
      "source": [
        "## Let's put everything together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f92e0b-1c54-489b-b8dd-41ebaafb380a",
      "metadata": {
        "height": 79,
        "id": "d8f92e0b-1c54-489b-b8dd-41ebaafb380a"
      },
      "outputs": [],
      "source": [
        "from utils import get_router_query_engine\n",
        "\n",
        "query_engine = get_router_query_engine(\"metagpt.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1a43f3-77dc-472a-8adc-56551c00a0ff",
      "metadata": {
        "height": 62,
        "id": "ec1a43f3-77dc-472a-8adc-56551c00a0ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f32ff1",
      "metadata": {
        "id": "46f32ff1"
      },
      "source": [
        "# Lesson 2: Tool Calling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea07c665",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fb345ad0",
      "metadata": {
        "id": "fb345ad0"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5bbf530-3f05-434c-a70f-ac2cc4b8f7aa",
      "metadata": {
        "id": "c5bbf530-3f05-434c-a70f-ac2cc4b8f7aa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from helper import get_openai_api_key\n",
        "OPENAI_API_KEY = get_openai_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c06c95-e8b2-4574-b14d-685876aa1c47",
      "metadata": {
        "id": "d4c06c95-e8b2-4574-b14d-685876aa1c47",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e53c064",
      "metadata": {
        "id": "2e53c064"
      },
      "source": [
        "## 1. Define a Simple Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071b717a-93cc-4332-b357-59a693359563",
      "metadata": {
        "id": "071b717a-93cc-4332-b357-59a693359563",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "def add(x: int, y: int) -> int:\n",
        "    \"\"\"Adds two integers together.\"\"\"\n",
        "    return x + y\n",
        "\n",
        "def mystery(x: int, y: int) -> int:\n",
        "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
        "    return (x + y) * (x + y)\n",
        "\n",
        "\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e62118-992b-4629-9022-be8c628209c1",
      "metadata": {
        "id": "d4e62118-992b-4629-9022-be8c628209c1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "response = llm.predict_and_call(\n",
        "    [add_tool, mystery_tool],\n",
        "    \"Tell me the output of the mystery function on 2 and 9\",\n",
        "    verbose=True\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb8a835",
      "metadata": {
        "id": "8cb8a835"
      },
      "source": [
        "## 2. Define an Auto-Retrieval Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6589123f",
      "metadata": {
        "id": "6589123f"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcdea238",
      "metadata": {
        "id": "bcdea238",
        "tags": []
      },
      "source": [
        "To download this paper, below is the needed code:\n",
        "\n",
        "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
        "\n",
        "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe9326c-d7b3-452b-ae52-12f000157be4",
      "metadata": {
        "id": "fbe9326c-d7b3-452b-ae52-12f000157be4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5451f0a3-d0a6-4b5c-a337-8e1a343ff5f0",
      "metadata": {
        "id": "5451f0a3-d0a6-4b5c-a337-8e1a343ff5f0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0fe0a9c-1f87-4ae7-a79e-7c3cf9c395ed",
      "metadata": {
        "id": "e0fe0a9c-1f87-4ae7-a79e-7c3cf9c395ed",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(nodes[0].get_content(metadata_mode=\"all\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7965cba-67b8-4cca-8e5f-2b0dbc96f6b0",
      "metadata": {
        "id": "d7965cba-67b8-4cca-8e5f-2b0dbc96f6b0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560f319c-8479-40c5-9b55-480fef98deb7",
      "metadata": {
        "id": "560f319c-8479-40c5-9b55-480fef98deb7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.vector_stores import MetadataFilters\n",
        "\n",
        "query_engine = vector_index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    filters=MetadataFilters.from_dicts(\n",
        "        [\n",
        "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"What are some high-level results of MetaGPT?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da4042f-8fdb-4959-8760-86685c903cfd",
      "metadata": {
        "id": "2da4042f-8fdb-4959-8760-86685c903cfd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30bb264c-42e0-46f8-9d28-da11a8535960",
      "metadata": {
        "id": "30bb264c-42e0-46f8-9d28-da11a8535960",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c392482",
      "metadata": {
        "id": "6c392482"
      },
      "source": [
        "### Define the Auto-Retrieval Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2639e79b-f615-425b-85ea-8a279bb26dd0",
      "metadata": {
        "id": "2639e79b-f615-425b-85ea-8a279bb26dd0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from llama_index.core.vector_stores import FilterCondition\n",
        "\n",
        "\n",
        "def vector_query(\n",
        "    query: str,\n",
        "    page_numbers: List[str]\n",
        ") -> str:\n",
        "    \"\"\"Perform a vector search over an index.\n",
        "\n",
        "    query (str): the string query to be embedded.\n",
        "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
        "        over all pages. Otherwise, filter by the set of specified pages.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    metadata_dicts = [\n",
        "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
        "    ]\n",
        "\n",
        "    query_engine = vector_index.as_query_engine(\n",
        "        similarity_top_k=2,\n",
        "        filters=MetadataFilters.from_dicts(\n",
        "            metadata_dicts,\n",
        "            condition=FilterCondition.OR\n",
        "        )\n",
        "    )\n",
        "    response = query_engine.query(query)\n",
        "    return response\n",
        "\n",
        "\n",
        "vector_query_tool = FunctionTool.from_defaults(\n",
        "    name=\"vector_tool\",\n",
        "    fn=vector_query\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a408ace-cf25-425b-8248-7028ceabcd42",
      "metadata": {
        "id": "2a408ace-cf25-425b-8248-7028ceabcd42",
        "tags": []
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool],\n",
        "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec05565-6adf-4294-ba5c-b384220876ac",
      "metadata": {
        "id": "6ec05565-6adf-4294-ba5c-b384220876ac",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef4dec0",
      "metadata": {
        "id": "fef4dec0"
      },
      "source": [
        "## Let's add some other tools!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55dd32e5-e29f-42ed-839a-ca937fe4743e",
      "metadata": {
        "id": "55dd32e5-e29f-42ed-839a-ca937fe4743e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    name=\"summary_tool\",\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful if you want to get a summary of MetaGPT\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4228ca7c-42a0-494b-987b-5a1c5c584536",
      "metadata": {
        "id": "4228ca7c-42a0-494b-987b-5a1c5c584536",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa3e8c1-a8c3-4c92-a0e4-5c081f91d966",
      "metadata": {
        "id": "4aa3e8c1-a8c3-4c92-a0e4-5c081f91d966",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21906d47-7266-4479-bbb4-9f392d5c399b",
      "metadata": {
        "id": "21906d47-7266-4479-bbb4-9f392d5c399b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"What is a summary of the paper?\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ec2f0f",
      "metadata": {
        "id": "64ec2f0f"
      },
      "source": [
        "# Lesson 3: Building an Agent Reasoning Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d7f1cf",
      "metadata": {
        "id": "b0d7f1cf"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07baa43-7a51-4c39-91cc-aa0d9619b69f",
      "metadata": {
        "height": 47,
        "id": "b07baa43-7a51-4c39-91cc-aa0d9619b69f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from helper import get_openai_api_key\n",
        "OPENAI_API_KEY = get_openai_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfa86a3-c7f2-41fa-b8b6-5617659ec36a",
      "metadata": {
        "height": 47,
        "id": "dcfa86a3-c7f2-41fa-b8b6-5617659ec36a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3af4bb",
      "metadata": {
        "id": "7d3af4bb"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d8bfb34",
      "metadata": {
        "id": "3d8bfb34",
        "tags": []
      },
      "source": [
        "To download this paper, below is the needed code:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
        "```\n",
        "\n",
        "\n",
        "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb741560",
      "metadata": {
        "id": "fb741560"
      },
      "source": [
        "## Setup the Query Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77464fb2-5ace-4839-9032-a020df8d4259",
      "metadata": {
        "height": 79,
        "id": "77464fb2-5ace-4839-9032-a020df8d4259",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from utils import get_doc_tools\n",
        "\n",
        "vector_tool, summary_tool = get_doc_tools(\"metagpt.pdf\", \"metagpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40aae3fc",
      "metadata": {
        "id": "40aae3fc"
      },
      "source": [
        "## Setup Function Calling Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4f5199-d02c-47b0-a9ab-cf72c8a506a3",
      "metadata": {
        "height": 79,
        "id": "ff4f5199-d02c-47b0-a9ab-cf72c8a506a3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9365d78d-8e9f-4f22-8d57-35a4c6aa6baf",
      "metadata": {
        "height": 181,
        "id": "9365d78d-8e9f-4f22-8d57-35a4c6aa6baf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_tool, summary_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a9535d7-0baf-4905-ad16-5fb903d33b85",
      "metadata": {
        "height": 96,
        "id": "5a9535d7-0baf-4905-ad16-5fb903d33b85",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.query(\n",
        "    \"Tell me about the agent roles in MetaGPT, \"\n",
        "    \"and then how they communicate with each other.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcf74ec4-559f-4284-9ed0-817d26951c54",
      "metadata": {
        "height": 45,
        "id": "bcf74ec4-559f-4284-9ed0-817d26951c54",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b28c184-0b65-4e38-808e-d91a285aaefe",
      "metadata": {
        "height": 79,
        "id": "6b28c184-0b65-4e38-808e-d91a285aaefe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.chat(\n",
        "    \"Tell me about the evaluation datasets used.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9586cef-21b5-4732-b95d-619462b4aaf6",
      "metadata": {
        "height": 45,
        "id": "d9586cef-21b5-4732-b95d-619462b4aaf6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.chat(\"Tell me the results over one of the above datasets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc4e983",
      "metadata": {
        "id": "1cc4e983"
      },
      "source": [
        "## Lower-Level: Debuggability and Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55abad72-b189-471a-accc-1621fd19c804",
      "metadata": {
        "height": 130,
        "id": "55abad72-b189-471a-accc-1621fd19c804",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_tool, summary_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e911aa-4640-4f89-99c8-6cdf6aff07c6",
      "metadata": {
        "height": 96,
        "id": "18e911aa-4640-4f89-99c8-6cdf6aff07c6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "task = agent.create_task(\n",
        "    \"Tell me about the agent roles in MetaGPT, \"\n",
        "    \"and then how they communicate with each other.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eaf0b88-e03a-4dd9-91f6-f6f0c8758e64",
      "metadata": {
        "height": 45,
        "id": "5eaf0b88-e03a-4dd9-91f6-f6f0c8758e64",
        "tags": []
      },
      "outputs": [],
      "source": [
        "step_output = agent.run_step(task.task_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e77fac-8734-4071-a672-b3a9f30e2bf1",
      "metadata": {
        "height": 79,
        "id": "a8e77fac-8734-4071-a672-b3a9f30e2bf1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "completed_steps = agent.get_completed_steps(task.task_id)\n",
        "print(f\"Num completed for task {task.task_id}: {len(completed_steps)}\")\n",
        "print(completed_steps[0].output.sources[0].raw_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db8de410-4b82-4daf-93da-28da57cbb0bb",
      "metadata": {
        "height": 79,
        "id": "db8de410-4b82-4daf-93da-28da57cbb0bb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "upcoming_steps = agent.get_upcoming_steps(task.task_id)\n",
        "print(f\"Num upcoming steps for task {task.task_id}: {len(upcoming_steps)}\")\n",
        "upcoming_steps[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc352582-2c17-46ef-ba80-0f571e920c3c",
      "metadata": {
        "height": 79,
        "id": "dc352582-2c17-46ef-ba80-0f571e920c3c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "step_output = agent.run_step(\n",
        "    task.task_id, input=\"What about how agents share information?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be80661f-81b1-45fc-b0ba-33a04dae849b",
      "metadata": {
        "height": 62,
        "id": "be80661f-81b1-45fc-b0ba-33a04dae849b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "step_output = agent.run_step(task.task_id)\n",
        "print(step_output.is_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4496328c-e6d5-4722-a8df-78a73a441b3c",
      "metadata": {
        "height": 45,
        "id": "4496328c-e6d5-4722-a8df-78a73a441b3c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.finalize_response(task.task_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601d1bed-78b2-4512-87ac-aec5ce5d8494",
      "metadata": {
        "height": 30,
        "id": "601d1bed-78b2-4512-87ac-aec5ce5d8494",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b523e0a",
      "metadata": {
        "id": "0b523e0a"
      },
      "source": [
        "# Lesson 4: Building a Multi-Document Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a323703",
      "metadata": {
        "id": "1a323703"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9625ab2-71b6-4fd0-904e-42df80d3215f",
      "metadata": {
        "height": 47,
        "id": "b9625ab2-71b6-4fd0-904e-42df80d3215f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from helper import get_openai_api_key\n",
        "OPENAI_API_KEY = get_openai_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3221a474-5817-4db2-af46-e029042a75a5",
      "metadata": {
        "height": 47,
        "id": "3221a474-5817-4db2-af46-e029042a75a5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20adaa26",
      "metadata": {
        "id": "20adaa26"
      },
      "source": [
        "## 1. Setup an agent over 3 papers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48b71ff6",
      "metadata": {
        "id": "48b71ff6"
      },
      "source": [
        "**Note**: The pdf files are included with this lesson. To access these papers, go to the `File` menu and select`Open...`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed10a24b-d65c-4b98-a93a-94ccdb8900d0",
      "metadata": {
        "height": 215,
        "id": "ed10a24b-d65c-4b98-a93a-94ccdb8900d0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    \"metagpt.pdf\",\n",
        "    \"longlora.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d8f3185-3221-4b00-bd38-41d36e4a3307",
      "metadata": {
        "height": 164,
        "id": "0d8f3185-3221-4b00-bd38-41d36e4a3307",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from utils import get_doc_tools\n",
        "from pathlib import Path\n",
        "\n",
        "paper_to_tools_dict = {}\n",
        "for paper in papers:\n",
        "    print(f\"Getting tools for paper: {paper}\")\n",
        "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
        "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e541bdd-14e1-41b6-81b5-b1bfda078d07",
      "metadata": {
        "height": 45,
        "id": "0e541bdd-14e1-41b6-81b5-b1bfda078d07",
        "tags": []
      },
      "outputs": [],
      "source": [
        "initial_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff58c52",
      "metadata": {
        "height": 79,
        "id": "bff58c52"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2c6a9f",
      "metadata": {
        "height": 30,
        "id": "2f2c6a9f"
      },
      "outputs": [],
      "source": [
        "len(initial_tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a124a438-5609-402e-8642-69d1088cb9ad",
      "metadata": {
        "height": 181,
        "id": "a124a438-5609-402e-8642-69d1088cb9ad",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    initial_tools,\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17409d4c-05a9-4bf4-b74f-75135fa3cb6b",
      "metadata": {
        "height": 96,
        "id": "17409d4c-05a9-4bf4-b74f-75135fa3cb6b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.query(\n",
        "    \"Tell me about the evaluation dataset used in LongLoRA, \"\n",
        "    \"and then tell me about the evaluation results\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace340b1-761f-4058-be41-68cf131541e4",
      "metadata": {
        "height": 62,
        "id": "ace340b1-761f-4058-be41-68cf131541e4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.query(\"Give me a summary of both Self-RAG and LongLoRA\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eede70c",
      "metadata": {
        "id": "7eede70c"
      },
      "source": [
        "## 2. Setup an agent over 11 papers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18771e69",
      "metadata": {
        "id": "18771e69"
      },
      "source": [
        "### Download 11 ICLR papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d01d2c-547f-4054-b0fe-ed9b1a9cc3b5",
      "metadata": {
        "height": 487,
        "id": "60d01d2c-547f-4054-b0fe-ed9b1a9cc3b5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
        "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
        "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
        "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
        "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
        "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
        "    \"https://openreview.net/pdf?id=TpD2aG1h0D\"\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    \"metagpt.pdf\",\n",
        "    \"longlora.pdf\",\n",
        "    \"loftq.pdf\",\n",
        "    \"swebench.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "    \"zipformer.pdf\",\n",
        "    \"values.pdf\",\n",
        "    \"finetune_fair_diffusion.pdf\",\n",
        "    \"knowledge_card.pdf\",\n",
        "    \"metra.pdf\",\n",
        "    \"vr_mcl.pdf\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b77426cb",
      "metadata": {
        "id": "b77426cb",
        "tags": []
      },
      "source": [
        "To download these papers, below is the needed code:\n",
        "\n",
        "\n",
        "    #for url, paper in zip(urls, papers):\n",
        "         #!wget \"{url}\" -O \"{paper}\"\n",
        "    \n",
        "    \n",
        "**Note**: The pdf files are included with this lesson. To access these papers, go to the `File` menu and select`Open...`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5ee34d-02ac-4537-ae20-7ef6c5767172",
      "metadata": {
        "height": 164,
        "id": "ea5ee34d-02ac-4537-ae20-7ef6c5767172",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from utils import get_doc_tools\n",
        "from pathlib import Path\n",
        "\n",
        "paper_to_tools_dict = {}\n",
        "for paper in papers:\n",
        "    print(f\"Getting tools for paper: {paper}\")\n",
        "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
        "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e35d52c",
      "metadata": {
        "id": "4e35d52c"
      },
      "source": [
        "### Extend the Agent with Tool Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20154923-873e-4941-9a3a-4926ab5f9b8c",
      "metadata": {
        "height": 45,
        "id": "20154923-873e-4941-9a3a-4926ab5f9b8c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671582f9-70d7-4a8f-b813-58b2a068ca72",
      "metadata": {
        "height": 164,
        "id": "671582f9-70d7-4a8f-b813-58b2a068ca72",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# define an \"object\" index and retriever over these tools\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.objects import ObjectIndex\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    all_tools,\n",
        "    index_cls=VectorStoreIndex,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3929882-e9dc-46ca-b495-53e3ed60340e",
      "metadata": {
        "height": 45,
        "id": "c3929882-e9dc-46ca-b495-53e3ed60340e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba9cfecd-fe14-4da8-b9ba-b3d485d98a03",
      "metadata": {
        "height": 79,
        "id": "ba9cfecd-fe14-4da8-b9ba-b3d485d98a03",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = obj_retriever.retrieve(\n",
        "    \"Tell me about the eval dataset used in MetaGPT and SWE-Bench\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c270ffbf-69c7-48ea-a028-9ba25221cde5",
      "metadata": {
        "height": 30,
        "id": "c270ffbf-69c7-48ea-a028-9ba25221cde5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools[2].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc0a0b6-9858-4348-9ae0-1cd4160f3fb7",
      "metadata": {
        "height": 266,
        "id": "9cc0a0b6-9858-4348-9ae0-1cd4160f3fb7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    tool_retriever=obj_retriever,\n",
        "    llm=llm,\n",
        "    system_prompt=\"\"\" \\\n",
        "You are an agent designed to answer queries over a set of given papers.\n",
        "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
        "\n",
        "\"\"\",\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a250cf1a-e011-4994-bcca-4e0294f20864",
      "metadata": {
        "height": 113,
        "id": "a250cf1a-e011-4994-bcca-4e0294f20864",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.query(\n",
        "    \"Tell me about the evaluation dataset used \"\n",
        "    \"in MetaGPT and compare it against SWE-Bench\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8084c8cb-98ed-4835-aaa4-5b0c7254be6d",
      "metadata": {
        "height": 96,
        "id": "8084c8cb-98ed-4835-aaa4-5b0c7254be6d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = agent.query(\n",
        "    \"Compare and contrast the LoRA papers (LongLoRA, LoftQ). \"\n",
        "    \"Analyze the approach in each paper first. \"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
